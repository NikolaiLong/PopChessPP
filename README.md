# PopChessPP
Pop Chess, but even better

## Proposal
This project's purpose is to be a sandbox, the initial work towards a competitor of Google's Alpha Zero (chess CNN).
This project will be a success if an AI algorithm is produced that can decently play chess.

## Reason
I am making my first real step towards AI proficiency light heartedly, with a game. But, this is to give myself a physical representation of what I am modeling.
In the future I will apply my knowledge and skills in AI to produce models and material to pursuade the governing bodies to vote in favor of climate saving policies.
And, a further step forward, I will create an optimistic AI that can come up with solutions to our climate crisis that no one could have imagined.

## Method
I graduated from Virginia Tech with a B.S. in computer science; however, I only took a single class on AI. Therefore, this will be a learning process in it of itself.
I will be diving deep into textbooks used by the top institutes use for their AI classes and follow a model that becomes progressively more advanced with each phase.

## Initial Brain Storming
#### Act 1: Local Environment
Phase 1: MiniMax Decision Tree

Phase 2: Neural Network

Phase 3: Convolusional Neural Network

Phase 4: (Hypothetical) Convolusional Neural Network with Random Forrest Classification

#### Act 2: Cloud Environment
Phase 1: Neural Network

Phase 2: Convolusional Neural Network

Phase 3: (Hypothetical) Convolusional Neural Network with Random Forrest Classification

## Phases
In each phase,
1. research will be done on the algorithms to be implemented, primarily through textbook references
2. a database will be constructed for optimal data retreival
3. an algorithm for the rules of chess will be devised in coordination with the ML algorithm to be implemented

## Textbook Reference
#### C++

#### AI












# OLD REFERENCE BELOW... IGNORE

# ChessPP
migration of the Chess repository to C++ for improved algorithm performance

# Development Reference

#### ML
## AI Reference
* DeepLearning.AI https://www.deeplearning.ai/ - courses
* FastAI https://www.fast.ai/ - courses
* Neural Networks https://karpathy.ai/zero-to-hero.html?utm_source=tldrnewsletter - course
* Google's TensorFlow https://developers.google.com/machine-learning/crash-course - course
* Google AI https://ai.google/education/ - courses
* ML https://www.mygreatlearning.com/machine-learning/free-courses - courses
* University Courses https://www.edx.org/learn/machine-learning - courses
* ML Projects https://upskill.analyticsvidhya.com/bb-projects/?utm_source=sendinblue&utm_medium=email&utm_campaign=BlackbeltAwarenessNew_signups_non_openers13-Feb-2023projects_and_features__AB_Testing_copy&utm_content=projects%20and%20features - projects


## info
* reiforcement learning (interaction with environment taking actions to maximize reward or minimize risk)
  - Markov Decision Process
---->  [agent] ----->
|state   ^ reward   |action
|        |          |
<-- [environment] <--

OpenAI - Deep RL
https://spinningup.openai.com/en/latest/index.html

RL Docs
* Q-Learning https://en.wikipedia.org/wiki/Q-learning
* Temporal Difference https://en.wikipedia.org/wiki/Temporal_difference_learning
- https://smartlabai.medium.com/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc
- https://www.v7labs.com/blog/deep-reinforcement-learning-guide#:~:text=Reinforcement%20Learning%20is%20a%20type,to%20maximize%20the%20total%20reward.

### Level 1
* minimax decision tree [board] [black] [white] - {given rules}
- https://towardsdatascience.com/algorithms-revisited-part-7-decision-trees-alpha-beta-pruning-9b711b6bf109
- https://en.wikipedia.org/wiki/Minimax
- https://www.simplilearn.com/the-power-of-decision-trees-in-machine-learning-article

### Level 2
* neural network

### Level 3
* CNN with reinforcement learning

### Level 4 (hypothetical)
* CNN + random forest (for advanced feature classification)
- random forest: https://www.simplilearn.com/tutorials/machine-learning-tutorial/random-forest-algorithm
- https://www.frontiersin.org/articles/10.3389/fmolb.2019.00044/full
- https://www.nature.com/articles/s41598-022-15374-5

